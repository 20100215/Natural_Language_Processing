{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "   text = f.read()\n",
    "   doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "doc[:36]\n",
    "# Note: This prints the tokens. Each token is separated by a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can be done with list comprehension\n",
    "sents = [sent for sent in doc.sents]\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The man's hands were behind\n",
       "his back, the wrists bound with a cord.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[1]\n",
    "# Notice the sentence tokenizer does not split at new lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det the\n",
      "man NOUN poss man\n",
      "'s PART case 's\n",
      "hands NOUN nsubj hand\n",
      "were AUX ROOT be\n",
      "behind ADP prep behind\n",
      "\n",
      " SPACE dep \n",
      "\n",
      "his PRON poss his\n",
      "back NOUN pobj back\n",
      ", PUNCT punct ,\n",
      "the DET det the\n",
      "wrists NOUN appos wrist\n",
      "bound VERB acl bind\n",
      "with ADP prep with\n",
      "a DET det a\n",
      "cord NOUN pobj cord\n",
      ". PUNCT punct .\n",
      "  SPACE dep  \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in sents[1]:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          DET     det          the         \n",
      "man          NOUN    poss         man         \n",
      "'s           PART    case         's          \n",
      "hands        NOUN    nsubj        hand        \n",
      "were         AUX     ROOT         be          \n",
      "behind       ADP     prep         behind      \n",
      "\n",
      "            SPACE   dep          \n",
      "           \n",
      "his          PRON    poss         his         \n",
      "back         NOUN    pobj         back        \n",
      ",            PUNCT   punct        ,           \n",
      "the          DET     det          the         \n",
      "wrists       NOUN    appos        wrist       \n",
      "bound        VERB    acl          bind        \n",
      "with         ADP     prep         with        \n",
      "a            DET     det          a           \n",
      "cord         NOUN    pobj         cord        \n",
      ".            PUNCT   punct        .           \n",
      "             SPACE   dep                      \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "for token in sents[1]:\n",
    "    print(f'{token.text:{12}} {token.pos_:{7}} {token.dep_:{12}} {token.lemma_:{12}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "\n",
    "# Pattern to match: r\"swimming\\s*vigorously\"\n",
    "pattern = [{'LOWER': 'swimming'}, {'IS_SPACE': True, 'OP':'*'}, {'LOWER': 'vigorously'}]\n",
    "matcher.add('SwimmingVigorously', [pattern]) #Note: pattern is now the 2nd argument based on SpaCy v3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13245044497498710760, 1274, 1277), (13245044497498710760, 3609, 3612)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "found_matches = matcher(doc)\n",
    "found_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match #1\n",
      " By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and \n",
      "\n",
      "Match #2\n",
      "saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  His brain was as energetic \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ctr=0\n",
    "for (id, start, end) in found_matches:\n",
    "  ctr += 1\n",
    "  print(f'Match #{ctr}')\n",
    "  print(doc[start-10:end+10],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
      "\n",
      "by Ambrose Bierce\n",
      "\n",
      "I\n",
      "\n",
      "A man stood upon a railroad bridge in northern Alabama, looking down\n",
      "into the swift water twenty feet below.   0 36\n",
      "The man's hands were behind\n",
      "his back, the wrists bound with a cord.   36 54\n",
      "A rope closely encircled his\n",
      "neck.   54 63\n",
      "It was attached to a stout cross-timber above his head and the\n",
      "slack fell to the level of his knees.   63 88\n",
      "Some loose boards laid upon the\n",
      "ties supporting the rails of the railway supplied a footing for him\n",
      "and his executioners--two private soldiers of the Federal army,\n",
      "directed by a sergeant who in civil life may have been a deputy\n",
      "sheriff.   88 138\n"
     ]
    }
   ],
   "source": [
    "# Visualize the structure of doc.sents\n",
    "for i in range(5):\n",
    "  print(sents[i], sents[i].start, sents[i].end)\n",
    "\n",
    "# Observation: sent.start and sent.end contains the token indices to which the sent bound in a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 0\n",
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.   \n",
      "\n",
      "Match 0\n",
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ctr=0\n",
    "matches_list = found_matches.copy()\n",
    "# loop through sentences and check if match start and match end within the sent \n",
    "for sent in sents:\n",
    "  if matches_list[0][1] > sent.start and matches_list[0][2] < sent.end:\n",
    "    print(f\"Match {ctr}\")\n",
    "    print(sent, \"\\n\")\n",
    "    matches_list = matches_list[1:] # Remove first record\n",
    "    if not matches_list:  # list is empty after removing --> stop the loop\n",
    "      break\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
